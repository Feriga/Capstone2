{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e886d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a0e42",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a217a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b4e556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              int64\n",
       "Zip_Code                int64\n",
       "Dwelling_Type          object\n",
       "Nr_Bedrooms             int64\n",
       "Nr_Bathrooms          float64\n",
       "Approx_SQFT             int64\n",
       "Price_per_SqFt        float64\n",
       "Dwelling_Styles        object\n",
       "Year_Built              int64\n",
       "Approx_Lot_SqFt         int64\n",
       "Pool                   object\n",
       "HOA_Fee               float64\n",
       "Land_Lease_Fee         object\n",
       "Clubhouse_Rec_Room     object\n",
       "Basement               object\n",
       "RV_Gate                object\n",
       "List_Price              int64\n",
       "Sold_Price              int64\n",
       "Building_Style         object\n",
       "Gated_Community        object\n",
       "Workout_Facility       object\n",
       "Garage_Spaces         float64\n",
       "Carport_Spaces        float64\n",
       "Loan_Type              object\n",
       "Payment_Type           object\n",
       "HOA_Missing             int64\n",
       "Buyer_Concession      float64\n",
       "Seller_Concession     float64\n",
       "diff_List_Sold          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804c141",
   "metadata": {},
   "source": [
    "**Find if any column contains NaN values** -- looks like 'HOA_Fee' contains NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177732b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOA_Fee']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e7398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NaN values with 0 in HOA_Fee column\n",
    "df['HOA_Fee'] = df['HOA_Fee'].fillna(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339a92ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for Nan values. \n",
    "df.columns[df.isnull().any()].tolist()\n",
    "# it looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb7dbf",
   "metadata": {},
   "source": [
    "### 1. Turn categorical values in numerical using get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93038fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3117 entries, 0 to 3116\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Dwelling_Type       3117 non-null   object\n",
      " 1   Dwelling_Styles     3117 non-null   object\n",
      " 2   Pool                3117 non-null   object\n",
      " 3   Land_Lease_Fee      3117 non-null   object\n",
      " 4   Clubhouse_Rec_Room  3117 non-null   object\n",
      " 5   Basement            3117 non-null   object\n",
      " 6   RV_Gate             3117 non-null   object\n",
      " 7   Building_Style      3117 non-null   object\n",
      " 8   Gated_Community     3117 non-null   object\n",
      " 9   Workout_Facility    3117 non-null   object\n",
      " 10  Loan_Type           3117 non-null   object\n",
      " 11  Payment_Type        3117 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 292.3+ KB\n"
     ]
    }
   ],
   "source": [
    "only_objects = df.select_dtypes('object').info()  # there are 12 columns of object type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd05053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['Dwelling_Type'], dtype='int', prefix='Type')\n",
    "df = pd.get_dummies(df,columns=['Dwelling_Styles'], dtype='int',prefix='Style')\n",
    "df= pd.get_dummies(df,columns=['Pool'],dtype='int', prefix='Pool')\n",
    "df= pd.get_dummies(df,columns=['Land_Lease_Fee'],dtype='int', prefix='Land')\n",
    "df= pd.get_dummies(df,columns=['Clubhouse_Rec_Room'],dtype='int', prefix='Club')\n",
    "df= pd.get_dummies(df,columns=['Basement'], dtype='int',prefix='Base')\n",
    "df= pd.get_dummies(df,columns=['RV_Gate'], dtype='int', prefix='RV_Gate')\n",
    "df= pd.get_dummies(df,columns=['Building_Style'],dtype='int', prefix='Bldg_style')\n",
    "df= pd.get_dummies(df,columns=['Gated_Community'],dtype='int', prefix='Gated')\n",
    "df= pd.get_dummies(df,columns=['Workout_Facility'],dtype='int', prefix='Fittness')\n",
    "df= pd.get_dummies(df,columns=['Loan_Type'],dtype='int', prefix='Loan')\n",
    "df= pd.get_dummies(df,columns=['Payment_Type'],dtype='int', prefix='Payment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29440e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3117, 67)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54285d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3117 entries, 0 to 3116\n",
      "Data columns (total 67 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Unnamed: 0                         3117 non-null   int64  \n",
      " 1   Zip_Code                           3117 non-null   int64  \n",
      " 2   Nr_Bedrooms                        3117 non-null   int64  \n",
      " 3   Nr_Bathrooms                       3117 non-null   float64\n",
      " 4   Approx_SQFT                        3117 non-null   int64  \n",
      " 5   Price_per_SqFt                     3117 non-null   float64\n",
      " 6   Year_Built                         3117 non-null   int64  \n",
      " 7   Approx_Lot_SqFt                    3117 non-null   int64  \n",
      " 8   HOA_Fee                            3117 non-null   float64\n",
      " 9   List_Price                         3117 non-null   int64  \n",
      " 10  Sold_Price                         3117 non-null   int64  \n",
      " 11  Garage_Spaces                      3117 non-null   float64\n",
      " 12  Carport_Spaces                     3117 non-null   float64\n",
      " 13  HOA_Missing                        3117 non-null   int64  \n",
      " 14  Buyer_Concession                   3117 non-null   float64\n",
      " 15  Seller_Concession                  3117 non-null   float64\n",
      " 16  diff_List_Sold                     3117 non-null   int64  \n",
      " 17  Type_AF                            3117 non-null   int32  \n",
      " 18  Type_GT                            3117 non-null   int32  \n",
      " 19  Type_LS                            3117 non-null   int32  \n",
      " 20  Type_MD                            3117 non-null   int32  \n",
      " 21  Type_MM                            3117 non-null   int32  \n",
      " 22  Type_PH                            3117 non-null   int32  \n",
      " 23  Type_SF                            3117 non-null   int32  \n",
      " 24  Type_TH                            3117 non-null   int32  \n",
      " 25  Style_Attached                     3117 non-null   int32  \n",
      " 26  Style_Detached                     3117 non-null   int32  \n",
      " 27  Style_Stacked                      3117 non-null   int32  \n",
      " 28  Pool_Both                          3117 non-null   int32  \n",
      " 29  Pool_Community                     3117 non-null   int32  \n",
      " 30  Pool_Private                       3117 non-null   int32  \n",
      " 31  Pool_no_pool                       3117 non-null   int32  \n",
      " 32  Land_N                             3117 non-null   int32  \n",
      " 33  Land_Y                             3117 non-null   int32  \n",
      " 34  Club_No                            3117 non-null   int32  \n",
      " 35  Club_Yes                           3117 non-null   int32  \n",
      " 36  Base_N                             3117 non-null   int32  \n",
      " 37  Base_Y                             3117 non-null   int32  \n",
      " 38  RV_Gate_No                         3117 non-null   int32  \n",
      " 39  RV_Gate_Yes                        3117 non-null   int32  \n",
      " 40  Bldg_style_2-3-4 Plex              3117 non-null   int32  \n",
      " 41  Bldg_style_2-3-4 Plex · Clustered  3117 non-null   int32  \n",
      " 42  Bldg_style_Clustered               3117 non-null   int32  \n",
      " 43  Bldg_style_Clustered · High Rise   3117 non-null   int32  \n",
      " 44  Bldg_style_High Rise               3117 non-null   int32  \n",
      " 45  Bldg_style_Missing                 3117 non-null   int32  \n",
      " 46  Bldg_style_String                  3117 non-null   int32  \n",
      " 47  Gated_No                           3117 non-null   int32  \n",
      " 48  Gated_Yes                          3117 non-null   int32  \n",
      " 49  Fittness_No                        3117 non-null   int32  \n",
      " 50  Fittness_Yes                       3117 non-null   int32  \n",
      " 51  Loan_Carryback                     3117 non-null   int32  \n",
      " 52  Loan_Cash                          3117 non-null   int32  \n",
      " 53  Loan_Cash to Loan                  3117 non-null   int32  \n",
      " 54  Loan_Conventional                  3117 non-null   int32  \n",
      " 55  Loan_Exchange                      3117 non-null   int32  \n",
      " 56  Loan_FHA                           3117 non-null   int32  \n",
      " 57  Loan_Other                         3117 non-null   int32  \n",
      " 58  Loan_USDA                          3117 non-null   int32  \n",
      " 59  Loan_VA                            3117 non-null   int32  \n",
      " 60  Payment_Adjustable                 3117 non-null   int32  \n",
      " 61  Payment_Balloon                    3117 non-null   int32  \n",
      " 62  Payment_Fixed                      3117 non-null   int32  \n",
      " 63  Payment_Graduated                  3117 non-null   int32  \n",
      " 64  Payment_Interest Only              3117 non-null   int32  \n",
      " 65  Payment_Missing                    3117 non-null   int32  \n",
      " 66  Payment_Other                      3117 non-null   int32  \n",
      "dtypes: float64(7), int32(50), int64(10)\n",
      "memory usage: 1022.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84593188",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65540fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2181.8999999999996, 935.0999999999999)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual checking for the partition sizes for 70/30 split\n",
    "len(df) * .7, len(df) * .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08bab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning the data into training and testing in 70/30 splits, with predicted value is \"Sold_Price\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Sold_Price'), \n",
    "                                                    df.Sold_Price, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3228a1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2181, 66), (936, 66))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partition sizes are consistent with the manual partitioning sizes calculated above\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b477309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2181,), (936,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01cb61c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "Zip_Code                   int64\n",
       "Nr_Bedrooms                int64\n",
       "Nr_Bathrooms             float64\n",
       "Approx_SQFT                int64\n",
       "                          ...   \n",
       "Payment_Fixed              int32\n",
       "Payment_Graduated          int32\n",
       "Payment_Interest Only      int32\n",
       "Payment_Missing            int32\n",
       "Payment_Other              int32\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the `dtypes` attribute of `X_train` to verify all features are numeric\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f50e0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "Zip_Code                   int64\n",
       "Nr_Bedrooms                int64\n",
       "Nr_Bathrooms             float64\n",
       "Approx_SQFT                int64\n",
       "                          ...   \n",
       "Payment_Fixed              int32\n",
       "Payment_Graduated          int32\n",
       "Payment_Interest Only      int32\n",
       "Payment_Missing            int32\n",
       "Payment_Other              int32\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat this check for the test split in `X_test`\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbcd4b",
   "metadata": {},
   "source": [
    "### Determine how good the mean is as a predictor. Consider \"Average Sold Price\" is the best guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e494dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649888.3635946814"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the mean of `y_train`\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a4d2719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[649888.36359468]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate same thing by fitting the dummy regressor on the training data and calling mean strategy\n",
    "# Then print the object's `constant_` attribute and verify it's the same as the mean above\n",
    "\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a7123",
   "metadata": {},
   "source": [
    "How good is this? How closely does this match, or explain, the actual values? Metrics will help answering these questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec31967",
   "metadata": {},
   "source": [
    "### Metrics:  \n",
    "### R-squared or coefficient of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6283b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Calculate the R^2 \n",
    "def r_squared(y, ypred):\n",
    "    \"\"\"R-squared score.    \n",
    "    Calculate the R-squared, or coefficient of determination, of the input.\n",
    "    Arguments:\n",
    "               y -- the observed values\n",
    "               ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    ybar = np.sum(y) / len(y)            # I know I could have used np.mean(y)\n",
    "    sum_sq_tot = np.sum((y - ybar)**2)   # total sum of squares error\n",
    "    sum_sq_res = np.sum((y - ypred)**2)  # residual sum of squares error\n",
    "    R2 = 1.0 - sum_sq_res / sum_sq_tot\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276dcc7",
   "metadata": {},
   "source": [
    "Make the predictions by creating an array \"y_tr_pred\" of length equal to the size of the training set with each array element equal to the single value of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daabfff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([649888.36359468, 649888.36359468, 649888.36359468, 649888.36359468,\n",
       "       649888.36359468])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred_ = train_mean * np.ones(len(y_train)) # np.ones(len(y_train)) creates an array of ones with the same length as y_train\n",
    "y_tr_pred_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054959e",
   "metadata": {},
   "source": [
    "I can obtain same thing using the sklearn dummy regressor baseline model: dumb_reg = DummyRegressor(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68be7df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([649888.36359468, 649888.36359468, 649888.36359468, 649888.36359468,\n",
       "       649888.36359468])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097abaf4",
   "metadata": {},
   "source": [
    "The DummyRegressor produces exactly the same results and saves me from having to mess about broadcasting the mean (or whichever other statistic is called. It also gives an object with fit() and predict() methods as well, which can be used as conveniently as any other sklearn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79557a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared(y_train, y_tr_pred)  # call r_squared function defined previosuly, using arguments y_train, y_tr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a64f75",
   "metadata": {},
   "source": [
    "As expected, if I use the average value as my prediction, I get an $R^2$ of zero _on the training set_. What if I use this \"model\" to predict unseen values from the test set? Of course, the \"model\" is trained on the training set; I still use the training set mean as my prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24420497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0078084421886748245"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r_squared(y_test, y_te_pred)  # call r_squared function defined previosuly, using arguments y_test, y_te_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1254a2",
   "metadata": {},
   "source": [
    "Performance on a test set is expected to be slightly worse than on the training set. As I'm getting an  𝑅2\n",
    "  of zero on the training set, there's nowhere to go but negative!  -0.0078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53145039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e169110",
   "metadata": {},
   "source": [
    "Next: I use Metrics that summarise the difference between predicted and actual values which are mean absolute error and mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d34e4",
   "metadata": {},
   "source": [
    "This is very simply the average of the absolute errors:\n",
    "\n",
    "$$MAE = \\frac{1}{n}\\sum_i^n|y_i - \\hat{y}|$$\n",
    "\n",
    "𝑦̂ \n",
    "  are our predicted values for the depended variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d53980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MAE according to formula above\n",
    "\n",
    "def mae(y, ypred):\n",
    "    \"\"\"Mean absolute error.    \n",
    "    Calculate the mean absolute error of the arguments\n",
    "    Arguments:\n",
    "                  y -- the observed values\n",
    "                  ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    abs_error = np.abs(y - ypred)\n",
    "    mae = np.mean(abs_error)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d048b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347574.7837341418"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bb1fe96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313711.9215035054"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_test, y_te_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf97eb7",
   "metadata": {},
   "source": [
    "#### the MAE was less when used on test set compared to train set, which is against what was expected.  Test set is unseen so we generally expect Test MAE to be higher as it more difficult to perform well on unseen data.\n",
    " It might happen \"by chance\" that the test set is relatively easier (than the training set) for the model to score higher accuracy hence leading to lower Test MAE. Running 1000 different train/test splits or cross validations would be some exploration methods to further analyze. For now, I continue with sklearn metrics.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9768fc",
   "metadata": {},
   "source": [
    "Mean absolute error is one of the most intuitive of all the metrics, this essentially says that, on average, expect to be off by around $313711 if the guessed Sold_Price was based on an average of known values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbed13a",
   "metadata": {},
   "source": [
    "### Next metric: Mean Squared Error calculated below as :   \n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_i^n(y_i - \\hat{y})^2$$\n",
    "\n",
    "MSE is a common metric (and an important one internally for optimizing machine learning models), this is simply the average of the square of the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f2eb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE according to formula above\n",
    "\n",
    "def mse(y, ypred):\n",
    "    \"\"\"Mean square error.     \n",
    "    Calculate the mean square error of the arguments\n",
    "    Arguments:\n",
    "            y -- the observed values\n",
    "            ypred -- the predicted values\n",
    "    \"\"\"\n",
    "    sq_error = (y - ypred)**2\n",
    "    mse = np.mean(sq_error)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "320c9a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407213445225.1448"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb45a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306122830945.3079"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888934f",
   "metadata": {},
   "source": [
    "This result is consistent with the findings of MAE where against expectations, the MSE on test data was less than MSE on train data. Same conclusions apply here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6129a",
   "metadata": {},
   "source": [
    "To convert this back to the measurement space, take the square root, to form the root mean square error thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07ef4254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([638132.78024651, 553283.68035331])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([mse(y_train, y_tr_pred), mse(y_test, y_te_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975dcd4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0daf334",
   "metadata": {},
   "source": [
    "### sklearn.metrics: Calculate R-squared and Mean Absolute Error using sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5154b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0078084421886748245)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-squared\n",
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b25a7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347574.7837341418, 313711.9215035054)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute error\n",
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c377bea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407213445225.1448, 306122830945.3079)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squarred error\n",
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "405202c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set - sklearn\n",
    "r2_score(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e39cc0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0078084421886748245"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set - sklearn\n",
    "r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55813a84",
   "metadata": {},
   "source": [
    "Conclusion:  The two error metrics MSE and MAE are employed. The MSE is typically larger than MAE, it penalizes larger errors more (because of the squaring operation). On the other hand MAE is more robust to the outliers sinmce it considers absolute differences. Results are conforming with expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea3793",
   "metadata": {},
   "source": [
    "## Initial Models:  \n",
    "### Steps: \n",
    "#### 1)   Scaling, \n",
    "#### 2)    Train the model on the train split\n",
    "#### 3)    Make predictions using the model on both train and test splits\n",
    "#### 4)    Assess model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29311f56",
   "metadata": {},
   "source": [
    "First: Imputing missing feature (predictor) values\n",
    "####  Impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a23424af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                1580.0\n",
       "Zip_Code                 85207.0\n",
       "Nr_Bedrooms                  3.0\n",
       "Nr_Bathrooms                 2.0\n",
       "Approx_SQFT               1790.0\n",
       "                          ...   \n",
       "Payment_Fixed                1.0\n",
       "Payment_Graduated            0.0\n",
       "Payment_Interest Only        0.0\n",
       "Payment_Missing              0.0\n",
       "Payment_Other                0.0\n",
       "Length: 66, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_defaults_median = X_train.median()\n",
    "X_defaults_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656ca8e",
   "metadata": {},
   "source": [
    "Apply the imputation to both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7b7ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `X_train` and `X_test`'s `fillna()` method, passing `X_defaults_median` as the values to use\n",
    "#Assign the results to `X_tr` and `X_te`, respectively\n",
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bbc2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `X_train` and `X_test`'s `fillna()` method, passing `X_defaults_median` as the values to use\n",
    "#Assign the results to `X_tr` and `X_te`, respectively\n",
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869d47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efe43c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I have features measured in many different units, with numbers that vary by orders of magnitude, \n",
    "# I start off by scaling them to put them all on a consistent scale. The StandardScaler scales each feature to zero mean and \n",
    "# unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5436d19",
   "metadata": {},
   "source": [
    "### 1) Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a3f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "# then use it's `transform()` method to apply the scaling to both the train and test split\n",
    "# data (`X_tr` and `X_te`), naming the results `X_tr_scaled` and `X_te_scaled`, respectively\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496269d",
   "metadata": {},
   "source": [
    "### 2) Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c1b2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2ca3b",
   "metadata": {},
   "source": [
    "### 3)    Make predictions using the model on both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76733aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the `predict()` method of the model (`lm`) on both the (scaled) train and test data\n",
    "#Assign the predictions to `y_tr_pred` and `y_te_pred`, respectively\n",
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e3ba1",
   "metadata": {},
   "source": [
    "### 4)    Assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f85d9c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bddc9fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.669231771903539e-10, 8.46933903825334e-10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error scores using `sklearn`'s `mean_absolute_error` function\n",
    "# as I did above for R^2\n",
    "# MAE - train, test\n",
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8c98116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5054971750176088e-18, 1.4216289684009066e-18)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And also I do the same using `sklearn`'s `mean_squared_error`\n",
    "# MSE - train, test\n",
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "median_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0cc07e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.669231771903539e-10, 8.46933903825334e-10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e50c0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5054971750176088e-18, 1.4216289684009066e-18)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cedcea",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab5c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler(), \n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d311cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bc0f220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(pipe, 'fit'), hasattr(pipe, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063568fa",
   "metadata": {},
   "source": [
    "### Fit the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1946f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the pipe's `fit()` method with `X_train` and `y_train` as arguments\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288af7d0",
   "metadata": {},
   "source": [
    "#### Make predictions on the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8371a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = pipe.predict(X_train)\n",
    "y_te_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6881d",
   "metadata": {},
   "source": [
    "#### Assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba9cf851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b312b",
   "metadata": {},
   "source": [
    "### Assessing performance using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cedd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(pipe, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c4dfd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99921537, 0.99997671, 1.        , 0.99955058, 0.99922597])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cv_results['test_score']\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cc53424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((np.mean(cv_scores) - 2 * np.std(cv_scores), np.mean(cv_scores) + 2 * np.std(cv_scores)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72814d70",
   "metadata": {},
   "source": [
    "### Hyperparameter search using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39a9a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'simpleimputer', 'standardscaler', 'linearregression', 'simpleimputer__add_indicator', 'simpleimputer__copy', 'simpleimputer__fill_value', 'simpleimputer__keep_empty_features', 'simpleimputer__missing_values', 'simpleimputer__strategy', 'simpleimputer__verbose', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__positive'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call `pipe`'s `get_params()` method to get a dict of available parameters and print their names\n",
    "#using dict's `keys()` method\n",
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6eb01f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [k+1 for k in range(len(X_train.columns))]\n",
    "grid_params = {'selectkbest__k': k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27bde10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_cv = GridSearchCV(pipe, param_grid=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c62a80a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'selectkbest' for estimator Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n                ('standardscaler', StandardScaler()),\n                ('linearregression', LinearRegression())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 211, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 70, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 205, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'selectkbest' for estimator Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n                ('standardscaler', StandardScaler()),\n                ('linearregression', LinearRegression())]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr_grid_cv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'selectkbest' for estimator Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n                ('standardscaler', StandardScaler()),\n                ('linearregression', LinearRegression())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "lr_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508ee35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
